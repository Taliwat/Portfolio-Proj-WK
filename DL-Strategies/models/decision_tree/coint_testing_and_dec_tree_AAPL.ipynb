{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cointegration Testing Analysis and Decision Tree Modeling for the AAPL Stock**\n",
    "## In this notebook we start to bring things together from other sections of the project.  We combine our analyzed and preprocessed core_stock_data with our preprocessed and dynamically generated secondary stock data to perform cointegration testing to see if we can create cointegrated pairs, which we will add as separate features to use for our Decision Tree model.  We will also merge in our exogenous data for this Decision Tree model, data we haven't talked about a whole lot yet.  This data will aid in adding in another layer to the stock chains we want to create at the end output at the end of the Decision Tree based on their relationships.  We will use the output of the Decision Tree to read into how the stocks work with each other so we can start to formulate our trading strategy in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As with our other notebooks let's read in our data to use for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "from statsmodels.tsa.stattools import coint, adfuller\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Close_core  Volume_core  Open_core  High_core   Low_core  \\\n",
      "Date                                                                   \n",
      "2019-03-14   45.932499   94318000.0  45.974998  46.025002  45.639999   \n",
      "2019-03-15   46.529999  156171600.0  46.212502  46.832500  45.935001   \n",
      "2019-03-18   47.005001  104879200.0  46.450001  47.097500  46.447498   \n",
      "2019-03-19   46.632500  126585600.0  47.087502  47.247501  46.480000   \n",
      "2019-03-20   47.040001  124140800.0  46.557499  47.372501  46.182499   \n",
      "\n",
      "            SMA_core   EMA_core   RSI_core  BBM_core   BBU_core  ...  \\\n",
      "Date                                                             ...   \n",
      "2019-03-14  41.35925  42.219051  75.741602  41.35925  46.695085  ...   \n",
      "2019-03-15  41.50025  42.388107  76.985910  41.50025  47.003365  ...   \n",
      "2019-03-18  41.72940  42.569162  78.724282  41.72940  47.174667  ...   \n",
      "2019-03-19  41.92075  42.728509  73.527018  41.92075  47.369412  ...   \n",
      "2019-03-20  42.12190  42.897587  80.396901  42.12190  47.569044  ...   \n",
      "\n",
      "            Momentum_7_Lag_Avg_1_3_core  Momentum_7_Lag_Std_1_3_core  \\\n",
      "Date                                                                   \n",
      "2019-03-14                     2.049999                     0.601040   \n",
      "2019-03-15                     2.049999                     0.601040   \n",
      "2019-03-18                     2.474998                     0.601040   \n",
      "2019-03-19                     2.943333                     0.915770   \n",
      "2019-03-20                     3.394999                     0.490078   \n",
      "\n",
      "            Momentum_30_Lag_Avg_1_3_core  Momentum_30_Lag_Std_1_3_core  \\\n",
      "Date                                                                     \n",
      "2019-03-14                      4.619999                      0.212131   \n",
      "2019-03-15                      4.619999                      0.212131   \n",
      "2019-03-18                      4.769999                      0.212131   \n",
      "2019-03-19                      4.971666                      0.380143   \n",
      "2019-03-20                      4.704999                      0.799484   \n",
      "\n",
      "            Momentum_50_Lag_Avg_1_3_core  Momentum_50_Lag_Std_1_3_core  \\\n",
      "Date                                                                     \n",
      "2019-03-14                      7.049999                  1.000000e-10   \n",
      "2019-03-15                      7.049999                  1.000000e-10   \n",
      "2019-03-18                      7.049999                  1.000000e-10   \n",
      "2019-03-19                      8.519166                  2.544672e+00   \n",
      "2019-03-20                      9.358334                  2.211183e+00   \n",
      "\n",
      "            OBV_Lag_Avg_1_3_core  OBV_Lag_Std_1_3_core  Diff_Close_EMA_core  \\\n",
      "Date                                                                          \n",
      "2019-03-14          1.592191e+09          1.104300e+08             3.713448   \n",
      "2019-03-15          1.592191e+09          1.104300e+08             4.141891   \n",
      "2019-03-18          1.670277e+09          1.104300e+08             4.435839   \n",
      "2019-03-19          1.731265e+09          1.313626e+08             3.903991   \n",
      "2019-03-20          1.776087e+09          6.769383e+07             4.142414   \n",
      "\n",
      "            Ratio_Close_EMA_core  \n",
      "Date                              \n",
      "2019-03-14              1.087957  \n",
      "2019-03-15              1.097714  \n",
      "2019-03-18              1.104203  \n",
      "2019-03-19              1.091367  \n",
      "2019-03-20              1.096565  \n",
      "\n",
      "[5 rows x 153 columns]\n",
      "(13650, 153)\n",
      "           ticker   Close_sec  Volume_sec    Open_sec    High_sec     Low_sec  \\\n",
      "Date                                                                            \n",
      "2019-03-14    RMD  101.000000    972500.0  102.570000  102.570000  100.959999   \n",
      "2019-03-15    RMD  100.370003   2279400.0  100.900002  101.730003  100.199997   \n",
      "2019-03-18    RMD   97.400002   1915700.0  100.360001  100.610001   96.940002   \n",
      "2019-03-19    RMD   97.900002   1101100.0   97.660004   98.190002   97.070000   \n",
      "2019-03-20    RMD   98.809998   1467600.0   99.129997  100.800003   98.449997   \n",
      "\n",
      "             SMA_sec     EMA_sec    RSI_sec   BBM_sec  ...  \\\n",
      "Date                                                   ...   \n",
      "2019-03-14  104.9046  101.000000  63.818062  104.9046  ...   \n",
      "2019-03-15  104.9046  100.975294  63.818062  104.9046  ...   \n",
      "2019-03-18  104.9046  100.835087  63.818062  104.9046  ...   \n",
      "2019-03-19  104.9046  100.719985  63.818062  104.9046  ...   \n",
      "2019-03-20  104.9046  100.645084  63.818062  104.9046  ...   \n",
      "\n",
      "            Momentum_7_Lag_Avg_1_3_sec  Momentum_7_Lag_Std_1_3_sec  \\\n",
      "Date                                                                 \n",
      "2019-03-14                    0.419998                1.000000e-10   \n",
      "2019-03-15                    0.419998                1.000000e-10   \n",
      "2019-03-18                    0.419998                1.000000e-10   \n",
      "2019-03-19                    0.419998                1.000000e-10   \n",
      "2019-03-20                    0.419998                1.000000e-10   \n",
      "\n",
      "            Momentum_30_Lag_Avg_1_3_sec  Momentum_30_Lag_Std_1_3_sec  \\\n",
      "Date                                                                   \n",
      "2019-03-14                     2.940002                 1.000000e-10   \n",
      "2019-03-15                     2.940002                 1.000000e-10   \n",
      "2019-03-18                     2.940002                 1.000000e-10   \n",
      "2019-03-19                     2.940002                 1.000000e-10   \n",
      "2019-03-20                     2.940002                 1.000000e-10   \n",
      "\n",
      "            Momentum_50_Lag_Avg_1_3_sec  Momentum_50_Lag_Std_1_3_sec  \\\n",
      "Date                                                                   \n",
      "2019-03-14                    12.889999                 1.000000e-10   \n",
      "2019-03-15                    12.889999                 1.000000e-10   \n",
      "2019-03-18                    12.889999                 1.000000e-10   \n",
      "2019-03-19                    12.889999                 1.000000e-10   \n",
      "2019-03-20                    12.889999                 1.000000e-10   \n",
      "\n",
      "            OBV_Lag_Avg_1_3_sec  OBV_Lag_Std_1_3_sec  Diff_Close_EMA_sec  \\\n",
      "Date                                                                       \n",
      "2019-03-14         1.000000e-10         1.611779e+06        1.000000e-10   \n",
      "2019-03-15         1.000000e-10         1.611779e+06        1.000000e-10   \n",
      "2019-03-18         1.000000e-10         1.611779e+06        1.000000e-10   \n",
      "2019-03-19         1.000000e-10         2.100176e+06        1.000000e-10   \n",
      "2019-03-20         1.000000e-10         9.614140e+05        1.000000e-10   \n",
      "\n",
      "            Ratio_Close_EMA_sec  \n",
      "Date                             \n",
      "2019-03-14             1.000000  \n",
      "2019-03-15             0.994006  \n",
      "2019-03-18             0.965934  \n",
      "2019-03-19             0.972002  \n",
      "2019-03-20             0.981767  \n",
      "\n",
      "[5 rows x 153 columns]\n",
      "(266665, 153)\n",
      "            interest_rates_10yr         gold  copper    platinum  silver  \\\n",
      "Date                                                                       \n",
      "2019-01-01                2.661  1281.000000  2.6250  799.099976  15.542   \n",
      "2019-01-02                2.661  1281.000000  2.6250  799.099976  15.542   \n",
      "2019-01-03                2.554  1291.800049  2.5705  794.500000  15.706   \n",
      "2019-01-04                2.659  1282.699951  2.6515  822.000000  15.695   \n",
      "2019-01-07                2.682  1286.800049  2.6410  818.400024  15.669   \n",
      "\n",
      "            crude_oil  natural_gas    corn   wheat  volatility_index  ...  \\\n",
      "Date                                                                  ...   \n",
      "2019-01-01  46.540001        2.958  375.75  506.75         23.219999  ...   \n",
      "2019-01-02  46.540001        2.958  375.75  506.75         23.219999  ...   \n",
      "2019-01-03  47.090000        2.945  379.75  513.75         25.450001  ...   \n",
      "2019-01-04  47.959999        3.044  383.00  517.00         21.379999  ...   \n",
      "2019-01-07  48.520000        2.944  382.25  516.75         21.400000  ...   \n",
      "\n",
      "            vanguard_total_world_stock_etf_Diff  us_treasury_bond_etf_Lag_1  \\\n",
      "Date                                                                          \n",
      "2019-01-01                         1.000000e-10                   24.850000   \n",
      "2019-01-02                         1.000000e-10                   24.850000   \n",
      "2019-01-03                         1.000000e-10                   24.850000   \n",
      "2019-01-04                         2.089996e+00                   24.990000   \n",
      "2019-01-07                         4.100037e-01                   24.860001   \n",
      "\n",
      "            us_treasury_bond_etf_Lag_2  us_treasury_bond_etf_Lag_3  \\\n",
      "Date                                                                 \n",
      "2019-01-01                       24.85                       24.85   \n",
      "2019-01-02                       24.85                       24.85   \n",
      "2019-01-03                       24.85                       24.85   \n",
      "2019-01-04                       24.85                       24.85   \n",
      "2019-01-07                       24.99                       24.85   \n",
      "\n",
      "            us_treasury_bond_etf_MA_7  us_treasury_bond_etf_MA_30  \\\n",
      "Date                                                                \n",
      "2019-01-01                      24.84                   24.794333   \n",
      "2019-01-02                      24.84                   24.794333   \n",
      "2019-01-03                      24.84                   24.794333   \n",
      "2019-01-04                      24.84                   24.794333   \n",
      "2019-01-07                      24.84                   24.794333   \n",
      "\n",
      "            us_treasury_bond_etf_Std_7  us_treasury_bond_etf_Std_30  \\\n",
      "Date                                                                  \n",
      "2019-01-01                    0.078316                     0.064897   \n",
      "2019-01-02                    0.078316                     0.064897   \n",
      "2019-01-03                    0.078316                     0.064897   \n",
      "2019-01-04                    0.078316                     0.064897   \n",
      "2019-01-07                    0.078316                     0.064897   \n",
      "\n",
      "            us_treasury_bond_etf_RoC  us_treasury_bond_etf_Diff  \n",
      "Date                                                             \n",
      "2019-01-01              1.000000e-10               1.000000e-10  \n",
      "2019-01-02              1.000000e-10               1.000000e-10  \n",
      "2019-01-03              5.633778e-01               1.399994e-01  \n",
      "2019-01-04              1.000000e-10               1.000000e-10  \n",
      "2019-01-07              1.000000e-10               1.000000e-10  \n",
      "\n",
      "[5 rows x 180 columns]\n",
      "(1467, 180)\n"
     ]
    }
   ],
   "source": [
    "# Now let's access the main core_stock_data.csv file, as well as the secondary stock data and exo_data to all be used in this notebook!\n",
    "csv_path = os.path.join(project_root, 'data', 'core_stock_unscaled.csv')\n",
    "core_stock_data = pd.read_csv(csv_path, parse_dates=['Date'], index_col= 'Date')\n",
    "print(core_stock_data.head())\n",
    "print(core_stock_data.shape)\n",
    "\n",
    "csv_path = os.path.join(project_root, 'data', 'secondary_stocks_gen_filtered.csv')\n",
    "sec_stock_data = pd.read_csv(csv_path, parse_dates=['Date'], index_col= 'Date')\n",
    "print(sec_stock_data.head())\n",
    "print(sec_stock_data.shape)\n",
    "\n",
    "csv_path = os.path.join(project_root, 'data', 'exo_data_unscaled.csv')\n",
    "exo_data = pd.read_csv(csv_path, parse_dates=['Date'], index_col= 'Date')\n",
    "print(exo_data.head())\n",
    "print(exo_data.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's grab just our AAPL stock for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_data = core_stock_data[core_stock_data['Ticker'] == 'AAPL']\n",
    "\n",
    "# As a check make sure data is aligned with AAPL and sec_stock_data\n",
    "aapl_data = aapl_data.loc[sec_stock_data.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we are ready.  We have our core stock and our secondary stock data.  Before we do the cointegration tests we will perform a ADF (Augmented Dickey-Fuller) test to check for stationarity.  This will help our cointegration results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -25.057373959777124\n",
      "p-value: 0.0\n",
      "Critical Values: {'1%': -3.430374530859638, '5%': -2.8615508423302964, '10%': -2.5667757709800068}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform ADF Test on the 'Close' price column\n",
    "adf_result = adfuller(aapl_data['Close_core'])\n",
    "\n",
    "# Display ADF test results\n",
    "print('ADF Statistic:', adf_result[0])\n",
    "print('p-value:', adf_result[1])\n",
    "print('Critical Values:', adf_result[4])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's break down our results.  The ADF Statistic as a negative number is expected and a higher negative number here suggests stronger evidence against our hypothesis that the data is non-stationary.  The output here is fairly large which means the data is very likely to be stationary.  For the p value a value of 0 can occur when the ADF statistic is very large.  This value also aids in showing that the data is stationary.  Finally for the critical values as all being negative as well, this again shows that we can reject the null hypothesis and safely say that our AAPL data is stationary and move on with the next phase of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now since there are 200 stocks in our secondary stock data we will need to make a function to process the tests more efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Secondary_Ticker  T-Statistic   P_value  \\\n",
      "0                RMD    -0.814387  0.932787   \n",
      "1               AMAT    -2.290508  0.378299   \n",
      "2               JNPR    -2.632174  0.224915   \n",
      "3               DECK    -2.150604  0.449963   \n",
      "4                JBL    -1.825677  0.617168   \n",
      "..               ...          ...       ...   \n",
      "195               ON    -1.828137  0.615957   \n",
      "196             SWKS    -0.497450  0.964513   \n",
      "197              MCD    -2.279811  0.383669   \n",
      "198             ADSK    -0.781050  0.937149   \n",
      "199                A    -1.380142  0.804239   \n",
      "\n",
      "                                       Critical_Values  Cointegrated  \n",
      "0    [-3.9044872726627737, -3.340613212756168, -3.0...         False  \n",
      "1    [-3.9044872726627737, -3.340613212756168, -3.0...         False  \n",
      "2    [-3.9044872726627737, -3.340613212756168, -3.0...         False  \n",
      "3    [-3.9044872726627737, -3.340613212756168, -3.0...         False  \n",
      "4    [-3.9044872726627737, -3.340613212756168, -3.0...         False  \n",
      "..                                                 ...           ...  \n",
      "195  [-3.9044872726627737, -3.340613212756168, -3.0...         False  \n",
      "196  [-3.9044872726627737, -3.340613212756168, -3.0...         False  \n",
      "197  [-3.9044872726627737, -3.340613212756168, -3.0...         False  \n",
      "198  [-3.9044872726627737, -3.340613212756168, -3.0...         False  \n",
      "199  [-3.9044872726627737, -3.340613212756168, -3.0...         False  \n",
      "\n",
      "[200 rows x 5 columns]\n",
      "\n",
      "Cointegrated Pairs:\n",
      "    Secondary_Ticker  T-Statistic   P_value  \\\n",
      "15               AZN    -3.350304  0.048178   \n",
      "85               ROL    -3.338208  0.049692   \n",
      "173             VTRS    -3.453472  0.036749   \n",
      "\n",
      "                                       Critical_Values  Cointegrated  \n",
      "15   [-3.9044872726627737, -3.340613212756168, -3.0...          True  \n",
      "85   [-3.9044872726627737, -3.340613212756168, -3.0...          True  \n",
      "173  [-3.9044872726627737, -3.340613212756168, -3.0...          True  \n"
     ]
    }
   ],
   "source": [
    "# Let's make a function that runs the test for our core stock for each secondary stock we have generated.\n",
    "def cointegration_test(core_stock_data, sec_stock_data, core_ticker):\n",
    "    results = []\n",
    "    \n",
    "    core_data = core_stock_data[core_stock_data['Ticker'] == core_ticker]['Close_core']\n",
    "    \n",
    "    secondary_tickers = sec_stock_data['ticker'].unique()\n",
    "    \n",
    "    for ticker in secondary_tickers:\n",
    "        sec_data = sec_stock_data[sec_stock_data['ticker'] == ticker]['Close_sec']\n",
    "        \n",
    "        # As a check ensure the lengths match by trimming the larger series (if needed)\n",
    "        min_len = min(len(core_data), len(sec_data))\n",
    "        core_trimmed = core_data.iloc[-min_len:]\n",
    "        sec_trimmed = sec_data.iloc[-min_len:]\n",
    "        \n",
    "        # Perform the cointegration test.\n",
    "        coint_t, p_value, critical_values = coint(core_trimmed, sec_trimmed)\n",
    "        \n",
    "        # Append results to our results list\n",
    "        results.append({\n",
    "            'Secondary_Ticker' : ticker,\n",
    "            'T-Statistic' : coint_t,\n",
    "            'P_value' : p_value,\n",
    "            'Critical_Values' : critical_values,\n",
    "            'Cointegrated' : p_value < 0.05 # True if cointegrated\n",
    "        })\n",
    "\n",
    "    # Convert the results into a dataframe\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Call the function now and perform cointegration testing on subject core stock and all secondary stocks\n",
    "results_df = cointegration_test(core_stock_data, sec_stock_data, core_ticker='AAPL')\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "# Filter and display only the cointegrated pairs\n",
    "cointegrated_pairs = results_df[results_df['Cointegrated'] == True]\n",
    "print(\"\\nCointegrated Pairs:\")\n",
    "print(cointegrated_pairs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neat!  Out of our 200 secondary stocks that we generated and preprocessed, we have 3 cointegration pairs with our core stock!  For this notebook using AAPL as our core stock it looks like AZN, ROL, and VTRS (AstraZeneca PLC, Rollins Inc, and Viatris Inc respectively) are the cointegrated pairs as their p-value is less than 0.05 which is the deterministic stat for the cointegration test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok time for our Decision Tree models.  We have a lot of setup to do for them first too.  We need to rename our ticker feature columns in our core_stock_ and sec_stock_data dataframes so they don't overwrite each other, and we then need to merge all 3 of our datasets together.  We will be careful as to how since it is a lot of data at this point.  Once done we will integrate our cointegrated pair information into the new df so this information is fed into the Decision Tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec_ticker</th>\n",
       "      <th>Close_sec</th>\n",
       "      <th>Volume_sec</th>\n",
       "      <th>Open_sec</th>\n",
       "      <th>High_sec</th>\n",
       "      <th>Low_sec</th>\n",
       "      <th>SMA_sec</th>\n",
       "      <th>EMA_sec</th>\n",
       "      <th>RSI_sec</th>\n",
       "      <th>BBM_sec</th>\n",
       "      <th>...</th>\n",
       "      <th>Momentum_7_Lag_Std_1_3_sec</th>\n",
       "      <th>Momentum_30_Lag_Avg_1_3_sec</th>\n",
       "      <th>Momentum_30_Lag_Std_1_3_sec</th>\n",
       "      <th>Momentum_50_Lag_Avg_1_3_sec</th>\n",
       "      <th>Momentum_50_Lag_Std_1_3_sec</th>\n",
       "      <th>OBV_Lag_Avg_1_3_sec</th>\n",
       "      <th>OBV_Lag_Std_1_3_sec</th>\n",
       "      <th>Diff_Close_EMA_sec</th>\n",
       "      <th>Ratio_Close_EMA_sec</th>\n",
       "      <th>cointegrated_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-03-14</th>\n",
       "      <td>RMD</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>972500.0</td>\n",
       "      <td>102.570000</td>\n",
       "      <td>102.570000</td>\n",
       "      <td>100.959999</td>\n",
       "      <td>104.9046</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>63.818062</td>\n",
       "      <td>104.9046</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>2.940002</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>12.889999</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.611779e+06</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-15</th>\n",
       "      <td>RMD</td>\n",
       "      <td>100.370003</td>\n",
       "      <td>2279400.0</td>\n",
       "      <td>100.900002</td>\n",
       "      <td>101.730003</td>\n",
       "      <td>100.199997</td>\n",
       "      <td>104.9046</td>\n",
       "      <td>100.975294</td>\n",
       "      <td>63.818062</td>\n",
       "      <td>104.9046</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>2.940002</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>12.889999</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.611779e+06</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.994006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-18</th>\n",
       "      <td>RMD</td>\n",
       "      <td>97.400002</td>\n",
       "      <td>1915700.0</td>\n",
       "      <td>100.360001</td>\n",
       "      <td>100.610001</td>\n",
       "      <td>96.940002</td>\n",
       "      <td>104.9046</td>\n",
       "      <td>100.835087</td>\n",
       "      <td>63.818062</td>\n",
       "      <td>104.9046</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>2.940002</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>12.889999</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.611779e+06</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.965934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-19</th>\n",
       "      <td>RMD</td>\n",
       "      <td>97.900002</td>\n",
       "      <td>1101100.0</td>\n",
       "      <td>97.660004</td>\n",
       "      <td>98.190002</td>\n",
       "      <td>97.070000</td>\n",
       "      <td>104.9046</td>\n",
       "      <td>100.719985</td>\n",
       "      <td>63.818062</td>\n",
       "      <td>104.9046</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>2.940002</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>12.889999</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>2.100176e+06</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.972002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-20</th>\n",
       "      <td>RMD</td>\n",
       "      <td>98.809998</td>\n",
       "      <td>1467600.0</td>\n",
       "      <td>99.129997</td>\n",
       "      <td>100.800003</td>\n",
       "      <td>98.449997</td>\n",
       "      <td>104.9046</td>\n",
       "      <td>100.645084</td>\n",
       "      <td>63.818062</td>\n",
       "      <td>104.9046</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>2.940002</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>12.889999</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>9.614140e+05</td>\n",
       "      <td>1.000000e-10</td>\n",
       "      <td>0.981767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sec_ticker   Close_sec  Volume_sec    Open_sec    High_sec  \\\n",
       "Date                                                                    \n",
       "2019-03-14        RMD  101.000000    972500.0  102.570000  102.570000   \n",
       "2019-03-15        RMD  100.370003   2279400.0  100.900002  101.730003   \n",
       "2019-03-18        RMD   97.400002   1915700.0  100.360001  100.610001   \n",
       "2019-03-19        RMD   97.900002   1101100.0   97.660004   98.190002   \n",
       "2019-03-20        RMD   98.809998   1467600.0   99.129997  100.800003   \n",
       "\n",
       "               Low_sec   SMA_sec     EMA_sec    RSI_sec   BBM_sec  ...  \\\n",
       "Date                                                               ...   \n",
       "2019-03-14  100.959999  104.9046  101.000000  63.818062  104.9046  ...   \n",
       "2019-03-15  100.199997  104.9046  100.975294  63.818062  104.9046  ...   \n",
       "2019-03-18   96.940002  104.9046  100.835087  63.818062  104.9046  ...   \n",
       "2019-03-19   97.070000  104.9046  100.719985  63.818062  104.9046  ...   \n",
       "2019-03-20   98.449997  104.9046  100.645084  63.818062  104.9046  ...   \n",
       "\n",
       "            Momentum_7_Lag_Std_1_3_sec  Momentum_30_Lag_Avg_1_3_sec  \\\n",
       "Date                                                                  \n",
       "2019-03-14                1.000000e-10                     2.940002   \n",
       "2019-03-15                1.000000e-10                     2.940002   \n",
       "2019-03-18                1.000000e-10                     2.940002   \n",
       "2019-03-19                1.000000e-10                     2.940002   \n",
       "2019-03-20                1.000000e-10                     2.940002   \n",
       "\n",
       "            Momentum_30_Lag_Std_1_3_sec  Momentum_50_Lag_Avg_1_3_sec  \\\n",
       "Date                                                                   \n",
       "2019-03-14                 1.000000e-10                    12.889999   \n",
       "2019-03-15                 1.000000e-10                    12.889999   \n",
       "2019-03-18                 1.000000e-10                    12.889999   \n",
       "2019-03-19                 1.000000e-10                    12.889999   \n",
       "2019-03-20                 1.000000e-10                    12.889999   \n",
       "\n",
       "            Momentum_50_Lag_Std_1_3_sec  OBV_Lag_Avg_1_3_sec  \\\n",
       "Date                                                           \n",
       "2019-03-14                 1.000000e-10         1.000000e-10   \n",
       "2019-03-15                 1.000000e-10         1.000000e-10   \n",
       "2019-03-18                 1.000000e-10         1.000000e-10   \n",
       "2019-03-19                 1.000000e-10         1.000000e-10   \n",
       "2019-03-20                 1.000000e-10         1.000000e-10   \n",
       "\n",
       "            OBV_Lag_Std_1_3_sec  Diff_Close_EMA_sec  Ratio_Close_EMA_sec  \\\n",
       "Date                                                                       \n",
       "2019-03-14         1.611779e+06        1.000000e-10             1.000000   \n",
       "2019-03-15         1.611779e+06        1.000000e-10             0.994006   \n",
       "2019-03-18         1.611779e+06        1.000000e-10             0.965934   \n",
       "2019-03-19         2.100176e+06        1.000000e-10             0.972002   \n",
       "2019-03-20         9.614140e+05        1.000000e-10             0.981767   \n",
       "\n",
       "            cointegrated_flag  \n",
       "Date                           \n",
       "2019-03-14                  0  \n",
       "2019-03-15                  0  \n",
       "2019-03-18                  0  \n",
       "2019-03-19                  0  \n",
       "2019-03-20                  0  \n",
       "\n",
       "[5 rows x 154 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First let's rename our two columns.\n",
    "core_stock_data.rename(columns = {'Ticker' : 'core_ticker'}, inplace = True)\n",
    "sec_stock_data.rename(columns = {'ticker' : 'sec_ticker'}, inplace = True)\n",
    "\n",
    "# Now let's make a variable that we can use for our cointegrated pairs\n",
    "cointegrated_stocks = ['AZN', 'ROL', 'VTRS'] # To be edited for each core stock's results.\n",
    "# Now let's make a single column that will have a binary '1' for when the cointegrated stock pair appears.\n",
    "sec_stock_data['cointegrated_flag'] = sec_stock_data['sec_ticker'].apply(lambda x: 1 if x in cointegrated_stocks else 0)\n",
    "\n",
    "sec_stock_data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The new feature column has been added on the end of our sec_stock_data and the column renaming is done.  Let's move on to merging.  Deep breath!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 59.0 GiB for an array with shape (152, 52101601) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 20\u001b[0m\n\u001b[0;32m     14\u001b[0m sec_exo_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(sec_stock_data, exo_data, how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#print(sec_exo_data.head())\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#print(sec_exo_data.shape)\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# One more, since we are focused on just one core stock at a time let's merge its data only with sec_stock_data and exo_data.\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m aapl_sec_exo_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43maapl_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msec_exo_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(aapl_sec_exo_data\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\ryanm\\Desktop\\Portfolio-Proj-WK\\DL-Strategies\\DL-Strat\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ryanm\\Desktop\\Portfolio-Proj-WK\\DL-Strategies\\DL-Strat\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_and_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright_indexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32mc:\\Users\\ryanm\\Desktop\\Portfolio-Proj-WK\\DL-Strategies\\DL-Strat\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:848\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    840\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m _items_overlap_with_suffix(\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuffixes\n\u001b[0;32m    842\u001b[0m )\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[1;32m--> 848\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m \u001b[43mleft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    850\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_indexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[43monly_slice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_dups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_na_proxy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    857\u001b[0m     left \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(lmgr, axes\u001b[38;5;241m=\u001b[39mlmgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    858\u001b[0m left\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m join_index\n",
      "File \u001b[1;32mc:\\Users\\ryanm\\Desktop\\Portfolio-Proj-WK\\DL-Strategies\\DL-Strat\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:687\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\ryanm\\Desktop\\Portfolio-Proj-WK\\DL-Strategies\\DL-Strat\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:688\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[0;32m    681\u001b[0m         indexer,\n\u001b[0;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[0;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[0;32m    685\u001b[0m     )\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 688\u001b[0m         \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m    693\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[0;32m    696\u001b[0m     ]\n\u001b[0;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[1;32mc:\\Users\\ryanm\\Desktop\\Portfolio-Proj-WK\\DL-Strategies\\DL-Strat\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[1;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[0;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[1;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43malgos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake_nd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_fill\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[0;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[0;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[0;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[0;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ryanm\\Desktop\\Portfolio-Proj-WK\\DL-Strategies\\DL-Strat\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[0;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[1;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_take_nd_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_fill\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ryanm\\Desktop\\Portfolio-Proj-WK\\DL-Strategies\\DL-Strat\\Lib\\site-packages\\pandas\\core\\array_algos\\take.py:157\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[1;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[0;32m    155\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[0;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[0;32m    161\u001b[0m )\n\u001b[0;32m    162\u001b[0m func(arr, indexer, out, fill_value)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 59.0 GiB for an array with shape (152, 52101601) and data type float64"
     ]
    }
   ],
   "source": [
    "# First merge, core_stock_data with sec_stock_data.\n",
    "#coresec_data = pd.merge(core_stock_data, sec_stock_data, how = 'left', left_index=True, right_index=True)\n",
    "\n",
    "#print(coresec_data.head())\n",
    "#print(coresec_data.shape)\n",
    "\n",
    "# Next is the new coresec_data with our exo_data.\n",
    "#coresec_exo_data = pd.merge(coresec_data, exo_data, how = 'left', left_index=True, right_index=True)\n",
    "\n",
    "#print(coresec_exo_data.head())\n",
    "#print(coresec_exo_data.shape)\n",
    "\n",
    "# Finally merge sec_stock_data with exo_data, as we will need this here for setting up our model.\n",
    "sec_exo_data = pd.merge(sec_stock_data, exo_data, how = 'left', on = 'Date')\n",
    "\n",
    "#print(sec_exo_data.head())\n",
    "#print(sec_exo_data.shape)\n",
    "\n",
    "# One more, since we are focused on just one core stock at a time let's merge its data only with sec_stock_data and exo_data.\n",
    "aapl_sec_exo_data = pd.merge(aapl_data, sec_exo_data, how = 'left', on = 'Date')\n",
    "\n",
    "print(aapl_sec_exo_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alright that's a big step accomplished, and we have compiled a lot of data (almost 1.3B values!).  Let's set up our Decision Tree model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will now set up our X,y for the model.  Similar to how we did for the Linear Regression models in this project we will eschew the traditional train_test_split methodology in favor of a more straightforward approach that works well with time series data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's set up our Decision Tree model and get it ready.\n",
    "X = coresec_exo_data.drop(['Close_core', 'core_ticker', 'sec_ticker'], axis = 1) # ALL the features and data minus the target\n",
    "y = aapl_data['Close_core'] # Our target\n",
    "\n",
    "# Now create the X,y for train and test for time series.\n",
    "split_index = int(len(X) * 0.8)\n",
    "\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok let's now instantiate the model and prep for the initial run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Decision Tree model itself.\n",
    "dec_tree = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Set up the parameter grid for tuning if needed.\n",
    "param_grid = {\n",
    "    'max_depth' : [3, 5, 6],\n",
    "    'min_samples_split' : [10, 20, 30],\n",
    "    'min_samples_leaf' : [5, 10, 15]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(dec_tree, param_grid, cv = 3, scoring = 'neg_mean_squared_error', n_jobs = -1)\n",
    "\n",
    "# Fit the model.\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's get the best model and run it again on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "best_tree.fit(X_train, y_train)\n",
    "\n",
    "# Now we can make predictions\n",
    "y_train_pred = best_tree.predict(X_train)\n",
    "y_test_pred = best_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL-Strat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
